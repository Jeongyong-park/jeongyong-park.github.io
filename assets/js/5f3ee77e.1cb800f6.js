"use strict";(self.webpackChunkjeongyong_park_github_io=self.webpackChunkjeongyong_park_github_io||[]).push([[4406],{2369:(e,l,i)=>{i.d(l,{A:()=>n});let n=i.p+"assets/images/lm-studio-ui-219c3578dcd863f8e7af130076d015f8.webp"},4040:(e,l,i)=>{i.r(l),i.d(l,{assets:()=>t,contentTitle:()=>{},default:()=>c,frontMatter:()=>r,metadata:()=>n,toc:()=>h});var n=i(8107),d=i(4848),s=i(8453);let r={title:"LM Studio: 내 PC에서 AI 언어모델을 자유롭게 실행하는 방법",date:"2025-06-02T13:00:00",authors:["jypark"],image:"/img/blog/lm-studio-hero.png",tags:["ai","llm","lm-studio","local-ai","machine-learning"],description:"LM Studio를 사용해 로컬 PC에서 AI 언어모델을 안전하고 비용 효율적으로 실행하는 완벽 가이드. 설치부터 활용까지 모든 과정을 상세히 소개합니다.",slug:"lm-studio-local-ai-guide",hide_table_of_contents:!1,hide_reading_time:!1},t={authorsImageUrls:[void 0]},h=[{value:"LM Studio란?",id:"lm-studio란",level:2},{value:"주요 특징과 장점",id:"주요-특징과-장점",level:2},{value:"🔒 완전 오프라인 사용",id:"-완전-오프라인-사용",level:3},{value:"🎨 사용자 친화적 UI",id:"-사용자-친화적-ui",level:3},{value:"🤖 다양한 모델 지원",id:"-다양한-모델-지원",level:3},{value:"🌐 로컬 서버 기능",id:"-로컬-서버-기능",level:3},{value:"💰 비용 효율성",id:"-비용-효율성",level:3},{value:"설치 및 시작 방법",id:"설치-및-시작-방법",level:2},{value:"1. 다운로드 및 설치",id:"1-다운로드-및-설치",level:3},{value:"2. 모델 다운로드",id:"2-모델-다운로드",level:3},{value:"3. 모델 실행 및 채팅",id:"3-모델-실행-및-채팅",level:3},{value:"실제 테스트 결과",id:"실제-테스트-결과",level:2},{value:"첫 번째 테스트: DeepSeek R1-distill-qwen-7b",id:"첫-번째-테스트-deepseek-r1-distill-qwen-7b",level:3},{value:"두 번째 테스트: DeepSeek R1-0528",id:"두-번째-테스트-deepseek-r1-0528",level:3},{value:"테스트 환경",id:"테스트-환경",level:3},{value:"시스템 요구사항",id:"시스템-요구사항",level:2},{value:"최소 사양",id:"최소-사양",level:3},{value:"권장 사양",id:"권장-사양",level:3},{value:"LM Studio가 적합한 사용자",id:"lm-studio가-적합한-사용자",level:2},{value:"🔬 AI 연구자/개발자",id:"-ai-연구자개발자",level:3},{value:"🛡️ 프라이버시 중시 사용자",id:"️-프라이버시-중시-사용자",level:3},{value:"🎓 AI 입문자/취미 개발자",id:"-ai-입문자취미-개발자",level:3},{value:"Ollama와의 비교",id:"ollama와의-비교",level:2},{value:"실제 활용 사례",id:"실제-활용-사례",level:2},{value:"💻 코드 리뷰 및 생성",id:"-코드-리뷰-및-생성",level:3},{value:"📝 문서 작성 지원",id:"-문서-작성-지원",level:3},{value:"🌍 언어 학습 및 번역",id:"-언어-학습-및-번역",level:3},{value:"🎯 맞춤형 AI 어시스턴트",id:"-맞춤형-ai-어시스턴트",level:3},{value:"성능 최적화 팁",id:"성능-최적화-팁",level:2},{value:"하드웨어 최적화",id:"하드웨어-최적화",level:3},{value:"모델 선택 전략",id:"모델-선택-전략",level:3},{value:"주의사항",id:"주의사항",level:2},{value:"기타 고려사항",id:"기타-고려사항",level:3},{value:"결론",id:"결론",level:2},{value:"참고 자료",id:"참고-자료",level:2}];function a(e){let l={a:"a",admonition:"admonition",blockquote:"blockquote",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,d.jsxs)(d.Fragment,{children:[(0,d.jsx)(l.p,{children:(0,d.jsx)(l.img,{alt:"LM Studio Hero",src:i(7010).A+"",width:"1536",height:"1024"})}),"\n",(0,d.jsxs)(l.p,{children:["AI와 LLM(대규모 언어 모델)에 관심이 있지만, 클라우드 서비스의 비용이나 개인정보 유출이 걱정된다면? ",(0,d.jsx)(l.strong,{children:"LM Studio"}),"는 로컬 컴퓨터에서 직접 LLM을 실행하고 실험할 수 있게 해주는 강력한 데스크탑 애플리케이션입니다."]}),"\n",(0,d.jsxs)(l.blockquote,{children:["\n",(0,d.jsxs)(l.p,{children:[(0,d.jsx)(l.strong,{children:"TL;DR"}),": LM Studio는 내 PC에서 오프라인으로 AI 언어모델을 실행할 수 있는 사용자 친화적인 데스크탑 앱입니다. 개인정보 보호와 비용 절약을 동시에 해결하며, 복잡한 설정 없이 다양한 오픈소스 AI 모델을 쉽게 체험할 수 있습니다."]}),"\n"]}),"\n",(0,d.jsx)(l.h2,{id:"lm-studio란",children:"LM Studio란?"}),"\n",(0,d.jsx)(l.p,{children:"LM Studio는 Windows, macOS, Linux 등 다양한 운영체제에서 동작하며, 인터넷 연결 없이도 LLM을 내 PC에서 실행할 수 있는 프로그램입니다. Hugging Face 등에서 공개된 다양한 오픈소스 AI 모델(Llama, MPT, StarCoder 등)을 쉽게 다운로드하고, 설치와 구동까지 한 번에 처리할 수 있습니다."}),"\n",(0,d.jsx)(l.p,{children:"ChatGPT처럼 대화형 인터페이스를 제공해 누구나 쉽게 AI와 채팅하거나 실험해볼 수 있으며, 개발자라면 OpenAI API와 호환되는 로컬 서버 기능도 활용할 수 있습니다."}),"\n",(0,d.jsx)(l.h2,{id:"주요-특징과-장점",children:"주요 특징과 장점"}),"\n",(0,d.jsx)(l.h3,{id:"-완전-오프라인-사용",children:"🔒 완전 오프라인 사용"}),"\n",(0,d.jsx)(l.p,{children:"모델 다운로드 후에는 인터넷 없이도 AI를 사용할 수 있어 개인정보 보호에 탁월합니다. 민감한 데이터나 기업 내부 정보를 다룰 때 특히 유용합니다."}),"\n",(0,d.jsx)(l.h3,{id:"-사용자-친화적-ui",children:"🎨 사용자 친화적 UI"}),"\n",(0,d.jsx)(l.p,{children:"복잡한 명령어나 설정 없이도 직관적인 그래픽 인터페이스에서 모델 검색, 다운로드, 실행, 채팅이 가능합니다. 기술적 배경이 없어도 쉽게 시작할 수 있습니다."}),"\n",(0,d.jsx)(l.h3,{id:"-다양한-모델-지원",children:"🤖 다양한 모델 지원"}),"\n",(0,d.jsx)(l.p,{children:"Hugging Face의 다양한 GGML/GGUF 포맷 모델을 지원하며, 여러 모델을 동시에 로드해 비교하거나 용도별로 활용할 수 있습니다."}),"\n",(0,d.jsx)(l.h3,{id:"-로컬-서버-기능",children:"🌐 로컬 서버 기능"}),"\n",(0,d.jsx)(l.p,{children:"OpenAI API와 호환되는 로컬 HTTP 서버를 제공해, 기존 OpenAI API를 사용하는 애플리케이션과도 쉽게 연동할 수 있습니다."}),"\n",(0,d.jsx)(l.h3,{id:"-비용-효율성",children:"💰 비용 효율성"}),"\n",(0,d.jsx)(l.p,{children:"클라우드 기반 AI 서비스 대비 훨씬 저렴하게, 혹은 무료로 LLM을 활용할 수 있습니다. 초기 하드웨어 투자 후에는 추가 비용이 거의 발생하지 않습니다."}),"\n",(0,d.jsx)(l.h2,{id:"설치-및-시작-방법",children:"설치 및 시작 방법"}),"\n",(0,d.jsx)(l.h3,{id:"1-다운로드-및-설치",children:"1. 다운로드 및 설치"}),"\n",(0,d.jsxs)(l.p,{children:["LM Studio 공식 홈페이지(",(0,d.jsx)(l.a,{href:"https://lmstudio.ai",children:"lmstudio.ai"}),")에서 자신의 OS에 맞는 설치 파일을 다운로드합니다. 설치 과정은 일반적인 데스크탑 애플리케이션과 동일하게 간단합니다."]}),"\n",(0,d.jsx)(l.p,{children:(0,d.jsx)(l.img,{alt:"LM Studio 실행 화면",src:i(2369).A+"",width:"2334",height:"1548"})}),"\n",(0,d.jsx)(l.h3,{id:"2-모델-다운로드",children:"2. 모델 다운로드"}),"\n",(0,d.jsx)(l.p,{children:"프로그램을 실행하면 인기 모델을 추천받거나 직접 검색해 다운로드할 수 있습니다. 처음 사용자라면 Llama 2 7B 모델부터 시작하는 것을 권장합니다."}),"\n",(0,d.jsx)(l.admonition,{title:"시스템 메모리 확인 필수",type:"warning",children:(0,d.jsx)(l.p,{children:"사용하는 시스템의 비디오 메모리에 따라 실행할 수 있는 모델의 용량이 제한됩니다. 모델을 다운로드하기 전에 시스템의 VRAM을 먼저 확인하세요."})}),"\n",(0,d.jsx)(l.p,{children:(0,d.jsx)(l.img,{alt:"모델 다운로드 화면",src:i(4632).A+"",width:"2338",height:"1544"})}),"\n",(0,d.jsx)(l.h3,{id:"3-모델-실행-및-채팅",children:"3. 모델 실행 및 채팅"}),"\n",(0,d.jsx)(l.p,{children:"모델을 다운로드한 후에는 채팅 UI에서 바로 AI와 대화하거나, 로컬 서버를 시작해 API로도 활용할 수 있습니다."}),"\n",(0,d.jsx)(l.h2,{id:"실제-테스트-결과",children:"실제 테스트 결과"}),"\n",(0,d.jsx)(l.h3,{id:"첫-번째-테스트-deepseek-r1-distill-qwen-7b",children:"첫 번째 테스트: DeepSeek R1-distill-qwen-7b"}),"\n",(0,d.jsx)(l.p,{children:"4.68GB 크기의 DeepSeek R1-distill-qwen-7b 모델로 첫 테스트를 진행했습니다."}),"\n",(0,d.jsx)(l.p,{children:(0,d.jsx)(l.img,{alt:"첫 번째 채팅 테스트",src:i(9958).A+"",width:"2336",height:"1540"})}),"\n",(0,d.jsx)(l.p,{children:'한국어로 "안녕"을 입력했으나, 모델에서는 한국어 "안녕!"과 함께 알 수 없는 문자가 추가로 출력되었습니다. 한국어 처리에 한계가 있는 것으로 보입니다.'}),"\n",(0,d.jsx)(l.h3,{id:"두-번째-테스트-deepseek-r1-0528",children:"두 번째 테스트: DeepSeek R1-0528"}),"\n",(0,d.jsx)(l.p,{children:"더 최신 버전인 DeepSeek R1-0528 모델로 재테스트를 진행했습니다."}),"\n",(0,d.jsx)(l.p,{children:(0,d.jsx)(l.img,{alt:"두 번째 채팅 테스트",src:i(9025).A+"",width:"2334",height:"1548"})}),"\n",(0,d.jsx)(l.p,{children:"간단한 질문에 28.31초가 소요되었지만, 정상적인 한글 문장으로 답변이 생성되었습니다. 오프라인 환경에서 로컬 노트북이 AI 답변을 생성한다는 점은 놀랍지만, 응답 속도는 아쉬운 부분입니다."}),"\n",(0,d.jsx)(l.h3,{id:"테스트-환경",children:"테스트 환경"}),"\n",(0,d.jsx)(l.p,{children:(0,d.jsx)(l.img,{alt:"하드웨어 사양",src:i(7680).A+"",width:"2334",height:"1548"})}),"\n",(0,d.jsx)(l.p,{children:"테스트에 사용된 노트북은 100만원대의 평범한 AMD CPU 계열 내장그래픽으로, VRAM이 512MB에 불과해 원활한 테스트에는 한계가 있었습니다."}),"\n",(0,d.jsx)(l.p,{children:"하지만 고성능 하드웨어를 보유한 사용자라면 인터넷 서비스를 거치지 않고 자체 장비에서 AI 모델을 구동하여 채팅은 물론, Cursor나 다른 Llama 계열 API를 사용하는 프로그램과도 연동할 수 있을 것입니다."}),"\n",(0,d.jsx)(l.h2,{id:"시스템-요구사항",children:"시스템 요구사항"}),"\n",(0,d.jsx)(l.h3,{id:"최소-사양",children:"최소 사양"}),"\n",(0,d.jsxs)(l.ul,{children:["\n",(0,d.jsxs)(l.li,{children:[(0,d.jsx)(l.strong,{children:"macOS"}),": M1/M2/M3 칩, macOS 13.6 이상"]}),"\n",(0,d.jsxs)(l.li,{children:[(0,d.jsx)(l.strong,{children:"Windows/Linux"}),": AVX2 지원 CPU, 8GB RAM, 4GB 이상 VRAM"]}),"\n"]}),"\n",(0,d.jsx)(l.h3,{id:"권장-사양",children:"권장 사양"}),"\n",(0,d.jsxs)(l.ul,{children:["\n",(0,d.jsxs)(l.li,{children:[(0,d.jsx)(l.strong,{children:"RAM"}),": 16GB 이상 (큰 모델의 경우 32GB 권장)"]}),"\n",(0,d.jsxs)(l.li,{children:[(0,d.jsx)(l.strong,{children:"GPU"}),": NVIDIA RTX 시리즈 또는 Apple Silicon 칩"]}),"\n",(0,d.jsxs)(l.li,{children:[(0,d.jsx)(l.strong,{children:"저장공간"}),": 모델 크기에 따라 10GB~100GB 이상"]}),"\n"]}),"\n",(0,d.jsx)(l.p,{children:"더 큰 모델이나 빠른 응답을 원한다면 고성능 GPU와 충분한 메모리가 필수입니다."}),"\n",(0,d.jsx)(l.h2,{id:"lm-studio가-적합한-사용자",children:"LM Studio가 적합한 사용자"}),"\n",(0,d.jsx)(l.h3,{id:"-ai-연구자개발자",children:"🔬 AI 연구자/개발자"}),"\n",(0,d.jsx)(l.p,{children:"다양한 LLM을 실험하고, API 연동을 통해 애플리케이션에 통합하고 싶은 개발자에게 이상적입니다."}),"\n",(0,d.jsx)(l.h3,{id:"️-프라이버시-중시-사용자",children:"🛡️ 프라이버시 중시 사용자"}),"\n",(0,d.jsx)(l.p,{children:"내 데이터가 외부로 전송되지 않는 완전한 오프라인 환경이 필요한 사용자에게 적합합니다."}),"\n",(0,d.jsx)(l.h3,{id:"-ai-입문자취미-개발자",children:"🎓 AI 입문자/취미 개발자"}),"\n",(0,d.jsx)(l.p,{children:"복잡한 설정 없이 쉽게 LLM을 체험하고 학습하고 싶은 분들에게 훌륭한 시작점이 됩니다."}),"\n",(0,d.jsx)(l.h2,{id:"ollama와의-비교",children:"Ollama와의 비교"}),"\n",(0,d.jsxs)(l.table,{children:[(0,d.jsx)(l.thead,{children:(0,d.jsxs)(l.tr,{children:[(0,d.jsx)(l.th,{children:"특징"}),(0,d.jsx)(l.th,{children:"LM Studio"}),(0,d.jsx)(l.th,{children:"Ollama"})]})}),(0,d.jsxs)(l.tbody,{children:[(0,d.jsxs)(l.tr,{children:[(0,d.jsx)(l.td,{children:"인터페이스"}),(0,d.jsx)(l.td,{children:"그래픽(GUI)"}),(0,d.jsx)(l.td,{children:"명령줄(CLI)"})]}),(0,d.jsxs)(l.tr,{children:[(0,d.jsx)(l.td,{children:"모델 지원"}),(0,d.jsx)(l.td,{children:"다양한 GGML/GGUF 모델"}),(0,d.jsx)(l.td,{children:"특정 모델 최적화"})]}),(0,d.jsxs)(l.tr,{children:[(0,d.jsx)(l.td,{children:"오픈소스 여부"}),(0,d.jsx)(l.td,{children:"비오픈소스"}),(0,d.jsx)(l.td,{children:"완전 오픈소스"})]}),(0,d.jsxs)(l.tr,{children:[(0,d.jsx)(l.td,{children:"API"}),(0,d.jsx)(l.td,{children:"OpenAI 호환 API 제공"}),(0,d.jsx)(l.td,{children:"REST API 제공"})]}),(0,d.jsxs)(l.tr,{children:[(0,d.jsx)(l.td,{children:"플랫폼"}),(0,d.jsx)(l.td,{children:"Windows, Mac, Linux"}),(0,d.jsx)(l.td,{children:"Mac, Linux, Windows"})]}),(0,d.jsxs)(l.tr,{children:[(0,d.jsx)(l.td,{children:"사용 편의성"}),(0,d.jsx)(l.td,{children:"초보자 친화적"}),(0,d.jsx)(l.td,{children:"개발자 중심"})]}),(0,d.jsxs)(l.tr,{children:[(0,d.jsx)(l.td,{children:"모델 관리"}),(0,d.jsx)(l.td,{children:"GUI 기반 직관적 관리"}),(0,d.jsx)(l.td,{children:"CLI 명령어 기반"})]})]})]}),"\n",(0,d.jsx)(l.p,{children:"LM Studio는 GUI를 선호하는 사용자에게, Ollama는 CLI 환경에 익숙한 개발자에게 더 적합합니다."}),"\n",(0,d.jsx)(l.h2,{id:"실제-활용-사례",children:"실제 활용 사례"}),"\n",(0,d.jsx)(l.h3,{id:"-코드-리뷰-및-생성",children:"💻 코드 리뷰 및 생성"}),"\n",(0,d.jsx)(l.p,{children:"StarCoder나 CodeLlama 모델을 사용해 코드 리뷰, 버그 찾기, 코드 생성 등의 작업을 로컬에서 안전하게 수행할 수 있습니다."}),"\n",(0,d.jsx)(l.h3,{id:"-문서-작성-지원",children:"📝 문서 작성 지원"}),"\n",(0,d.jsx)(l.p,{children:"기술 문서, 블로그 포스트, 이메일 등의 작성을 도와주는 개인 AI 어시스턴트로 활용할 수 있습니다."}),"\n",(0,d.jsx)(l.h3,{id:"-언어-학습-및-번역",children:"🌍 언어 학습 및 번역"}),"\n",(0,d.jsx)(l.p,{children:"다양한 언어로 대화하며 언어 학습을 지원하거나, 번역 작업을 수행할 수 있습니다."}),"\n",(0,d.jsx)(l.h3,{id:"-맞춤형-ai-어시스턴트",children:"🎯 맞춤형 AI 어시스턴트"}),"\n",(0,d.jsx)(l.p,{children:"특정 도메인에 특화된 모델을 사용해 전문 분야의 질문 답변이나 분석 작업을 수행할 수 있습니다."}),"\n",(0,d.jsx)(l.h2,{id:"성능-최적화-팁",children:"성능 최적화 팁"}),"\n",(0,d.jsx)(l.h3,{id:"하드웨어-최적화",children:"하드웨어 최적화"}),"\n",(0,d.jsxs)(l.ul,{children:["\n",(0,d.jsxs)(l.li,{children:[(0,d.jsx)(l.strong,{children:"GPU 가속 활용"}),": CUDA(NVIDIA) 또는 Metal(Apple) 가속을 활성화해 성능 향상"]}),"\n",(0,d.jsxs)(l.li,{children:[(0,d.jsx)(l.strong,{children:"메모리 관리"}),": 다른 애플리케이션을 종료해 더 많은 메모리 확보"]}),"\n",(0,d.jsxs)(l.li,{children:[(0,d.jsx)(l.strong,{children:"SSD 사용"}),": 모델 로딩 속도 향상을 위해 SSD에 모델 저장"]}),"\n"]}),"\n",(0,d.jsx)(l.h3,{id:"모델-선택-전략",children:"모델 선택 전략"}),"\n",(0,d.jsxs)(l.ul,{children:["\n",(0,d.jsxs)(l.li,{children:[(0,d.jsx)(l.strong,{children:"7B 모델부터 시작"}),": 처음에는 작은 모델로 시작해 점진적으로 업그레이드"]}),"\n",(0,d.jsxs)(l.li,{children:[(0,d.jsx)(l.strong,{children:"양자화 모델 활용"}),": Q4_K_M, Q5_K_M 등 양자화된 모델로 메모리 사용량 절약"]}),"\n",(0,d.jsxs)(l.li,{children:[(0,d.jsx)(l.strong,{children:"용도별 모델 선택"}),": 코딩용, 대화용, 번역용 등 목적에 맞는 모델 선택"]}),"\n"]}),"\n",(0,d.jsx)(l.h2,{id:"주의사항",children:"주의사항"}),"\n",(0,d.jsx)(l.admonition,{title:"라이선스 확인 필수",type:"danger",children:(0,d.jsx)(l.p,{children:"상업적 용도로 사용할 경우 각 모델의 라이선스를 반드시 확인하세요. 일부 모델은 상업적 사용이 제한될 수 있습니다."})}),"\n",(0,d.jsx)(l.h3,{id:"기타-고려사항",children:"기타 고려사항"}),"\n",(0,d.jsxs)(l.ul,{children:["\n",(0,d.jsxs)(l.li,{children:[(0,d.jsx)(l.strong,{children:"전력 소비"}),": 고성능 GPU 사용 시 전력 소비량이 크게 증가할 수 있습니다"]}),"\n",(0,d.jsxs)(l.li,{children:[(0,d.jsx)(l.strong,{children:"발열 관리"}),": 장시간 사용 시 시스템 발열에 주의하세요"]}),"\n",(0,d.jsxs)(l.li,{children:[(0,d.jsx)(l.strong,{children:"모델 업데이트"}),": 정기적으로 새로운 모델을 확인하고 업데이트하세요"]}),"\n"]}),"\n",(0,d.jsx)(l.h2,{id:"결론",children:"결론"}),"\n",(0,d.jsx)(l.p,{children:"LM Studio는 누구나 쉽고 안전하게 AI 언어모델을 체험하고, 나만의 AI 환경을 구축할 수 있는 최고의 로컬 LLM 도구입니다. 복잡한 설정 없이 내 PC에서 직접 AI를 만나보세요."}),"\n",(0,d.jsx)(l.p,{children:"개인정보 보호, 비용 절약, 사용 편의성을 모두 만족하는 LM Studio로 AI의 새로운 가능성을 탐험해보시기 바랍니다. 특히 개발자라면 로컬 API 서버 기능을 통해 기존 워크플로우에 쉽게 통합할 수 있어 더욱 유용할 것입니다."}),"\n",(0,d.jsx)(l.h2,{id:"참고-자료",children:"참고 자료"}),"\n",(0,d.jsxs)(l.ul,{children:["\n",(0,d.jsx)(l.li,{children:(0,d.jsx)(l.a,{href:"https://lmstudio.ai",children:"LM Studio 공식 홈페이지"})}),"\n",(0,d.jsx)(l.li,{children:(0,d.jsx)(l.a,{href:"https://huggingface.co/models",children:"Hugging Face 모델 허브"})}),"\n",(0,d.jsx)(l.li,{children:(0,d.jsx)(l.a,{href:"https://github.com/ggerganov/ggml",children:"GGML/GGUF 포맷 가이드"})}),"\n",(0,d.jsx)(l.li,{children:(0,d.jsx)(l.a,{href:"https://lmstudio.ai/docs",children:"LM Studio 공식 문서"})}),"\n",(0,d.jsx)(l.li,{children:(0,d.jsx)(l.a,{href:"https://github.com/ggerganov/llama.cpp",children:"로컬 LLM 성능 벤치마크"})}),"\n"]})]})}function c(e={}){let{wrapper:l}={...(0,s.R)(),...e.components};return l?(0,d.jsx)(l,{...e,children:(0,d.jsx)(a,{...e})}):a(e)}},4632:(e,l,i)=>{i.d(l,{A:()=>n});let n=i.p+"assets/images/model-download-64687dcf4766d1dc0d814e0622b2747c.webp"},7010:(e,l,i)=>{i.d(l,{A:()=>n});let n=i.p+"assets/images/lm-studio-hero-83d3868eb7cbebc980e1eedefa9c65a0.webp"},7680:(e,l,i)=>{i.d(l,{A:()=>n});let n=i.p+"assets/images/hardware-bfe1db2f6ef69431a628831402cf9a0e.webp"},8107:e=>{e.exports=JSON.parse('{"permalink":"/blog/lm-studio-local-ai-guide","source":"@site/blog/2025-06-02-post-2/index.md","title":"LM Studio: 내 PC에서 AI 언어모델을 자유롭게 실행하는 방법","description":"LM Studio를 사용해 로컬 PC에서 AI 언어모델을 안전하고 비용 효율적으로 실행하는 완벽 가이드. 설치부터 활용까지 모든 과정을 상세히 소개합니다.","date":"2025-06-02T13:00:00.000Z","tags":[{"inline":true,"label":"ai","permalink":"/blog/tags/ai"},{"inline":true,"label":"llm","permalink":"/blog/tags/llm"},{"inline":true,"label":"lm-studio","permalink":"/blog/tags/lm-studio"},{"inline":true,"label":"local-ai","permalink":"/blog/tags/local-ai"},{"inline":true,"label":"machine-learning","permalink":"/blog/tags/machine-learning"}],"readingTime":5,"hasTruncateMarker":true,"authors":[{"name":"Jeongyong Park","title":"쌍팔년생 개발자","url":"https://github.com/jeongyong-park","email":"kladess@gmail.com","socials":{"x":"https://x.com/chisquare88","github":"https://github.com/jeongyong-park"},"imageURL":"/img/avatar.webp","key":"jypark","page":null}],"frontMatter":{"title":"LM Studio: 내 PC에서 AI 언어모델을 자유롭게 실행하는 방법","date":"2025-06-02T13:00:00","authors":["jypark"],"image":"/img/blog/lm-studio-hero.png","tags":["ai","llm","lm-studio","local-ai","machine-learning"],"description":"LM Studio를 사용해 로컬 PC에서 AI 언어모델을 안전하고 비용 효율적으로 실행하는 완벽 가이드. 설치부터 활용까지 모든 과정을 상세히 소개합니다.","slug":"lm-studio-local-ai-guide","hide_table_of_contents":false,"hide_reading_time":false},"unlisted":false,"prevItem":{"title":"DiffX: 확장 가능한 차세대 Diff 형식","permalink":"/blog/diffx-next-generation-extensible-diff-format"},"nextItem":{"title":"C#에서 Thread와 Parallel.ForEach 안전하게 중단하는 방법","permalink":"/blog/csharp-thread-parallel-foreach-safe-cancellation"}}')},8453:(e,l,i)=>{i.d(l,{R:()=>r,x:()=>t});var n=i(6540);let d={},s=n.createContext(d);function r(e){let l=n.useContext(s);return n.useMemo((function(){return"function"==typeof e?e(l):{...l,...e}}),[l,e])}function t(e){let l;return l=e.disableParentContext?"function"==typeof e.components?e.components(d):e.components||d:r(e.components),n.createElement(s.Provider,{value:l},e.children)}},9025:(e,l,i)=>{i.d(l,{A:()=>n});let n=i.p+"assets/images/try-chat-2-bc8e1eb7df78db0fe5cfc13b10cbc5d9.webp"},9958:(e,l,i)=>{i.d(l,{A:()=>n});let n=i.p+"assets/images/try-chat-c44e619f8c5dba632bd086107d115779.webp"}}]);